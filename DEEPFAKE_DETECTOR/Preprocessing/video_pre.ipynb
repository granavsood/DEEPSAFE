{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4832,"status":"ok","timestamp":1741247905914,"user":{"displayName":"Dishant Saini","userId":"11980740334491300751"},"user_tz":-330},"id":"4DzyGkItdkZl","outputId":"3bca8554-0053-4c1c-a7ff-cd9e03d69e29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Collecting mtcnn\n","  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n","Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn) (1.4.2)\n","Collecting lz4>=4.3.3 (from mtcnn)\n","  Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lz4, mtcnn\n","Successfully installed lz4-4.4.3 mtcnn-1.0.0\n"]}],"source":["pip install opencv-python mtcnn tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zN5p0va2ddYm"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from mtcnn import MTCNN\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IkqOM8Otdr84"},"outputs":[],"source":["# Set input and output paths\n","INPUT_DIR = \"/content/drive/MyDrive/STUDY MATERIAL/MINOR_2/DFDC_FAKE_Face_only_data/\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/STUDY MATERIAL/MINOR_2/FF_Face_only_data/\"\n","FRAME_THRESHOLD = 100  # Limit number of frames\n","FRAME_SIZE = (112, 112)  # Resize output frames\n","FPS = 30  # Frames per second"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ea2OQGIgehCX"},"outputs":[],"source":["os.makedirs(OUTPUT_DIR, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58efVP0eejtr"},"outputs":[],"source":["detector = MTCNN()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7UswLkvbeu1I"},"outputs":[],"source":["def extract_faces(video_path, output_video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_list = []\n","    frame_count = 0\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret or frame_count >= FRAME_THRESHOLD:\n","            break  # Stop if the video ends or we reach the threshold\n","\n","        # Detect faces in frame\n","        faces = detector.detect_faces(frame)\n","        if faces:\n","            x, y, w, h = faces[0]['box']  # Get bounding box of the first detected face\n","            x, y = max(0, x), max(0, y)  # Ensure coordinates are positive\n","            cropped_face = frame[y:y + h, x:x + w]  # Crop the face region\n","\n","            # Resize to uniform size\n","            cropped_face = cv2.resize(cropped_face, FRAME_SIZE)\n","            frame_list.append(cropped_face)\n","\n","        frame_count += 1\n","\n","    cap.release()\n","\n","    # Ensure at least some frames are detected\n","    if len(frame_list) > 0:\n","        # Create output video file\n","        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MP4 format\n","        out = cv2.VideoWriter(output_video_path, fourcc, FPS, FRAME_SIZE)\n","\n","        # Write frames to video\n","        for frame in frame_list:\n","            out.write(frame)\n","\n","        out.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CSyQHybbewuv"},"outputs":[],"source":["# Process all videos in the dataset\n","video_files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.mp4')]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"CTlooNgSe6yb","outputId":"9114277c-5fad-49b2-bc1f-404b2e82b1a2"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing videos:  18%|█▊        | 289/1566 [59:58<4:25:29, 12.47s/it]"]}],"source":["for video_file in tqdm(video_files, desc=\"Processing videos\"):\n","    input_video_path = os.path.join(INPUT_DIR, video_file)\n","    output_video_path = os.path.join(OUTPUT_DIR, video_file)\n","\n","    extract_faces(input_video_path, output_video_path)\n","\n","print(\"Processing complete! All face-cropped videos saved.\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1fAcP411MoA_pXgLgshNKVKMhC8KOSdnO","authorship_tag":"ABX9TyM05jG6ZNMaf+a8NGmohBPW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}